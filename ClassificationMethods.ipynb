{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import util\n",
    "# Beautiful soup might be useful\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.linear_model import LogisticRegressionCV as LogRegCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import discriminant_analysis as da\n",
    "from sklearn import tree\n",
    "# from sklearn.cross_validation import cross_val_predict \n",
    "# from sklearn import cross_validation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from nltk.corpus import wordnet\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_regularized_scores(old_df):\n",
    "    new_df = old_df.copy()\n",
    "    new_df['std_score'] = new_df.groupby(['essay_set'])[['score']].apply(lambda x: (x - np.mean(x)) / (np.std(x)))\n",
    "    return new_df\n",
    "\n",
    "def create_regularization_data(old_df):\n",
    "    #getting the number of datasets\n",
    "    max_essay_set = max(old_df['essay_set'])\n",
    "    #list of the regularized values\n",
    "    regularization_data = []\n",
    "    for i in range(max_essay_set+1):\n",
    "        mean = np.mean((old_df[old_df['essay_set'] == i + 1])['score'])\n",
    "        std = np.std((old_df[old_df['essay_set'] == i + 1])['score'])\n",
    "        regularization_data.append([i + 1, mean, std])\n",
    "    return regularization_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularized data for each essay set =  [[1, 8.528323051037576, 1.5381336495587767], [2, 6.749444444444444, 1.3844371990179603], [3, 1.8482039397450754, 0.8149207612821795], [4, 1.4322033898305084, 0.9395167668768533], [5, 2.4088642659279778, 0.9705520523317599], [6, 2.72, 0.970360757656664], [7, 16.062460165710643, 4.583888354164165], [8, 36.95020746887967, 5.749521294509325], [9, nan, nan]]\n",
      "\n",
      "\n",
      "   essay_id  essay_set                                              essay  \\\n",
      "0         1          1  Dear local newspaper, I think effects computer...   \n",
      "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
      "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
      "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
      "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
      "\n",
      "   score  std_score  \n",
      "0      8  -0.343483  \n",
      "1      9   0.306655  \n",
      "2      7  -0.993622  \n",
      "3     10   0.956794  \n",
      "4      8  -0.343483  \n",
      "\n",
      "\n",
      "mean and standard deviation of essay set 1 =  5.145133400155731e-16 , 1.0000000000000064\n",
      "mean and standard deviation of essay set 2 =  1.8861455607242937e-16 , 1.0000000000000007\n",
      "mean and standard deviation of essay set 3 =  -8.542156296073047e-17 , 0.9999999999999976\n",
      "mean and standard deviation of essay set 4 =  -1.3303858956101453e-16 , 1.0000000000000004\n",
      "mean and standard deviation of essay set 5 =  1.1314433539046957e-16 , 0.999999999999986\n",
      "mean and standard deviation of essay set 6 =  -5.913787977836668e-16 , 0.9999999999999828\n",
      "mean and standard deviation of essay set 7 =  1.3200261647152516e-16 , 1.0000000000000007\n",
      "mean and standard deviation of essay set 8 =  -2.549059779913914e-17 , 1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Read in training data\n",
    "# Note that for essay set 2, score becomes average of 2 domain scores\n",
    "train_cols = ['essay_id', 'essay_set', 'essay', 'domain1_score', 'domain2_score']\n",
    "train_df = pd.read_csv('../../data/training_set_rel3.tsv',encoding = \"ISO-8859-1\", delimiter='\\t', usecols=train_cols)\n",
    "for i in range(train_df.shape[0]):\n",
    "    if not np.isnan(train_df.get_value(i, 'domain2_score')):\n",
    "        assert train_df.get_value(i, 'essay_set') == 2\n",
    "        new_val = train_df.get_value(i, 'domain1_score') + train_df.get_value(i, 'domain2_score')\n",
    "        train_df.set_value(i, 'domain1_score', new_val) \n",
    "train_df = train_df.drop('domain2_score', axis=1)\n",
    "train_df = train_df.rename(columns={'domain1_score': 'score'})\n",
    "\n",
    "################\n",
    "regularization_data = create_regularization_data(train_df)\n",
    "train_df = append_regularized_scores(train_df)\n",
    "\n",
    "print (\"The regularized data for each essay set = \", regularization_data)\n",
    "print (\"\\n\")\n",
    "\n",
    "#print train_df[train_df['essay_set'] == 2].head()\n",
    "print (train_df.head())\n",
    "print (\"\\n\")\n",
    "\n",
    "#validate that the standardization works\n",
    "max_essay_set = max(train_df['essay_set'])\n",
    "for i in range (max_essay_set):\n",
    "    valid = train_df[train_df[\"essay_set\"] == i + 1][\"std_score\"]\n",
    "    print (\"mean and standard deviation of essay set \" + str(i + 1) + \" = \", np.mean(valid), \",\", np.std(valid))\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   score  \n",
       "0      7  \n",
       "1      8  \n",
       "2      9  \n",
       "3      9  \n",
       "4      9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in validation data\n",
    "valid_cols = ['essay_id', 'essay_set', 'essay', 'domain1_predictionid', 'domain2_predictionid']\n",
    "valid_df = pd.read_csv('../../data/valid_set.tsv', delimiter='\\t', encoding = \"ISO-8859-1\",usecols=valid_cols)\n",
    "valid_df['score'] = pd.Series([0] * valid_df.shape[0], index=valid_df.index)\n",
    "\n",
    "# scores are stored in separate data set, we'll put them in same one\n",
    "valid_scores = pd.read_csv('../../data/valid_sample_submission_5_column.csv', encoding = \"ISO-8859-1\",delimiter=',')\n",
    "\n",
    "# put each score in our data set, and make sure to handle essay set 2\n",
    "for i in range(valid_df.shape[0]):\n",
    "    dom1_predid = valid_df.get_value(i, 'domain1_predictionid')\n",
    "    row = valid_scores[valid_scores['prediction_id'] == dom1_predid]\n",
    "    score = row.get_value(row.index[0], 'predicted_score')\n",
    "    \n",
    "    dom2_predid = valid_df.get_value(i, 'domain2_predictionid')\n",
    "    if not np.isnan(dom2_predid):\n",
    "        assert valid_df.get_value(i, 'essay_set') == 2\n",
    "        rowB = valid_scores[valid_scores['prediction_id'] == dom2_predid]\n",
    "        scoreB = rowB.get_value(rowB.index[0], 'predicted_score')\n",
    "        score += scoreB\n",
    "        \n",
    "    valid_df.set_value(i, 'score', score)\n",
    "        \n",
    "valid_df = valid_df.drop(['domain1_predictionid', 'domain2_predictionid'], axis=1)\n",
    "#print valid_df[valid_df['essay_set'] == 2].head()\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returned a copy of old_df, with essays cleaned for count vectorizer\n",
    "# cleaning returns essay with only lowercase words separated by space\n",
    "def vectorizer_clean(old_df):\n",
    "    new_df = old_df.copy()\n",
    "    for i in range(new_df.shape[0]):\n",
    "        new_df.set_value(i, 'essay', \" \".join(re.sub('[^a-zA-Z\\d\\s]', '', new_df['essay'].iloc[i]).lower().split())) \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dear local newspaper i think effects computers...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dear caps1 caps2 i believe that using computer...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.306655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>dear caps1 caps2 caps3 more and more people us...</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.993622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>dear local newspaper caps1 i have found that m...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.956794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>dear location1 i know having computers has a p...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  dear local newspaper i think effects computers...   \n",
       "1         2          1  dear caps1 caps2 i believe that using computer...   \n",
       "2         3          1  dear caps1 caps2 caps3 more and more people us...   \n",
       "3         4          1  dear local newspaper caps1 i have found that m...   \n",
       "4         5          1  dear location1 i know having computers has a p...   \n",
       "\n",
       "   score  std_score  \n",
       "0      8  -0.343483  \n",
       "1      9   0.306655  \n",
       "2      7  -0.993622  \n",
       "3     10   0.956794  \n",
       "4      8  -0.343483  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print essays cleaned for vectorizer (essay is now just lowercase words separated by space) \n",
    "vectorizer_train = vectorizer_clean(train_df)\n",
    "vectorizer_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>dear organization1 caps1 more and more people ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>dear location1 time caps1 me tell you what i t...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>dear local newspaper have you been spending a ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>dear readers caps1 you imagine how life would ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>dear newspaper i strongly believe that compute...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  dear organization1 caps1 more and more people ...   \n",
       "1      1789          1  dear location1 time caps1 me tell you what i t...   \n",
       "2      1790          1  dear local newspaper have you been spending a ...   \n",
       "3      1791          1  dear readers caps1 you imagine how life would ...   \n",
       "4      1792          1  dear newspaper i strongly believe that compute...   \n",
       "\n",
       "   score  \n",
       "0      7  \n",
       "1      8  \n",
       "2      9  \n",
       "3      9  \n",
       "4      9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print essays cleaned for vectorizer (essay is now just lowercase words separated by space) \n",
    "vectorizer_valid = vectorizer_clean(valid_df)\n",
    "vectorizer_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "#Get all the text from data\n",
    "train_essays = vectorizer_train['essay'].values\n",
    "\n",
    "#Turn each text into an array of word counts\n",
    "train_vectors = vectorizer.fit_transform(train_essays).toarray()\n",
    "\n",
    "#normalizing for y\n",
    "train_std_scores = np.asarray(vectorizer_train['std_score'], dtype=\"byte\")\n",
    "print (train_std_scores[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Classification Models\n",
    "\n",
    "Trying out LDA, QDA, Decision Trees, and Random Forests"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LDA = da.LinearDiscriminantAnalysis()\n",
    "QDA = da.QuadraticDiscriminantAnalysis()\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# visualize data and calculuate accuracy rates\n",
    "models = [LDA, QDA, dt, rf]\n",
    "model_title = ['LDA', 'QDA', 'dt', 'rf']\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    print (model_title[idx])\n",
    "    model.fit(train_vectors, train_std_scores)\n",
    "    print(idx)\n",
    "    valid_vectors = vectorizer.transform(vectorizer_valid['essay'].values).toarray()\n",
    "    valid_pred_std_scores = model.predict(valid_vectors)\n",
    "    print (valid_pred_std_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-220d6538b303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_std_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalid_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'essay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shrinkage not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lsqr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_lsqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36m_solve_svd\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;31m# 2) Within variance scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;31m# SVD of centered (within)scaled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LDA = da.LinearDiscriminantAnalysis()\n",
    "LDA.fit(train_vectors, train_std_scores)\n",
    "valid_vectors = vectorizer.transform(vectorizer_valid['essay'].values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_pred_std_scores_lda = LDA.predict(valid_vectors)\n",
    "# Appending predicted scores to validation data set\n",
    "valid_df[\"LDA predicted_scores\"] = valid_pred_std_scores_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l2 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['LDA predicted_scores']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_lda.append(int(float(value) * float(regularization_data[i][2]) + (regularization_data[i][1])))\n",
    "# print stand_pred_values_l2\n",
    "\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['newly_predicted_scores_LDA'] = stand_pred_values_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "#   Scoring   #\n",
    "###############\n",
    "\n",
    "#Scoring the predicted values with the actual values\n",
    "lda_count = 0\n",
    "for i in range(len(valid_df)):\n",
    "    if valid_df.iloc[i]['score'] == valid_df.iloc[i]['newly_predicted_scores_lda']:\n",
    "        lda_count += 1\n",
    "        \n",
    "print \"LDA\"\n",
    "print \"Number of correct predictions =\", lda_count\n",
    "print \"Total number of observations =\", len(valid_df)\n",
    "print \"Score =\", float(lda_count) / len(valid_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Misspelled words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input is list of words in text, output percentage spelling correct\n",
    "def percentage_correct_spelling(text):\n",
    "    text_len = len(text)\n",
    "    correct = 0\n",
    "    for word in text:\n",
    "        try:\n",
    "            if wordnet.synsets(word):\n",
    "                correct += 1\n",
    "        except:\n",
    "            correct+= 0\n",
    "    return 1. * correct / text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spelling_feature_x = []\n",
    "for train in train_essays:\n",
    "    sentence = train.split()\n",
    "    percent = percentage_correct_spelling(sentence)\n",
    "    spelling_feature_x.append([percent])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.685459940652819], [0.6945107398568019], [0.6989247311827957], [0.6335877862595419], [0.6752688172043011], [0.6219512195121951], [0.6833667334669339], [0.6804979253112033], [0.7013574660633484], [0.6673306772908366]]\n"
     ]
    }
   ],
   "source": [
    "print (spelling_feature_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6956521739130435], [0.6967741935483871], [0.6281179138321995], [0.6620498614958449], [0.7373068432671082], [0.6847826086956522], [0.7149220489977728], [0.6864864864864865], [0.7084745762711865], [0.6654545454545454]]\n"
     ]
    }
   ],
   "source": [
    "valid_essays = vectorizer_valid['essay'].values\n",
    "valid_spelling_x = []\n",
    "for valid in valid_essays:\n",
    "    sentence = valid.split()\n",
    "    percent = percentage_correct_spelling(sentence)\n",
    "    valid_spelling_x.append([percent])\n",
    "print (valid_spelling_x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Log Regression - spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1296: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=4,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_l2 = LogReg(penalty='l2', solver='liblinear', n_jobs=4)\n",
    "xs = np.array(spelling_feature_x)\n",
    "logistic_l2.fit(xs, train_std_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My guess is we will want to denormalize these scores for quadratic weighted k\n",
    "valid_pred_std_scores_l2 = logistic_l2.predict(valid_spelling_x)\n",
    "# Appending predicted scores to validation data set\n",
    "valid_df[\"Log_L2 predicted_scores\"] = valid_pred_std_scores_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l2 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['Log_L2 predicted_scores']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_l2.append(int(float(value) * float(regularization_data[i][2]) + (regularization_data[i][1])))\n",
    "#print (stand_pred_values_l2)\n",
    "\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['newly_predicted_scores_log_l2'] = stand_pred_values_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Log Reg - Spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1296: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=4,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_l1 = LogReg(penalty='l1', solver='liblinear', n_jobs=4)\n",
    "xs = np.array(spelling_feature_x)\n",
    "logistic_l1.fit(xs, train_std_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My guess is we will want to denormalize these scores for quadratic weighted k\n",
    "valid_pred_std_scores_l1 = logistic_l1.predict(valid_spelling_x)\n",
    "# Appending predicted scores to validation data set\n",
    "valid_df[\"Log_L1 predicted_scores\"] = valid_pred_std_scores_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l1 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['Log_L1 predicted_scores']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_l1.append(int(float(value) * float(regularization_data[i][2]) + (regularization_data[i][1])))\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['newly_predicted_scores_log_l1'] = stand_pred_values_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring with Spelling as Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC L2 using Feature: Spelling\n",
      "Number of correct predictions = 1273\n",
      "Total number of observations = 4218\n",
      "Score = 0.30180180180180183\n",
      "\n",
      "LOGISTIC L1 using Feature: Spelling\n",
      "Number of correct predictions = 1273\n",
      "Total number of observations = 4218\n",
      "Score = 0.30180180180180183\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "#   Scoring   #\n",
    "###############\n",
    "\n",
    "#Scoring the predicted values with the actual values\n",
    "log_l1_count = 0\n",
    "log_l2_count = 0\n",
    "for i in range(len(valid_df)):\n",
    "    if valid_df.iloc[i]['score'] == valid_df.iloc[i]['newly_predicted_scores_log_l2']:\n",
    "        log_l2_count += 1\n",
    "    if valid_df.iloc[i]['score'] == valid_df.iloc[i]['newly_predicted_scores_log_l1']:\n",
    "        log_l1_count += 1\n",
    "        \n",
    "print (\"LOGISTIC L2 using Feature: Spelling\")\n",
    "print (\"Number of correct predictions =\", log_l2_count)\n",
    "print (\"Total number of observations =\", len(valid_df))\n",
    "print (\"Score =\", float(log_l2_count) / len(valid_df))\n",
    "\n",
    "print (\"\")\n",
    "print (\"LOGISTIC L1 using Feature: Spelling\")\n",
    "print (\"Number of correct predictions =\", log_l1_count)\n",
    "print (\"Total number of observations =\", len(valid_df))\n",
    "print (\"Score =\", float(log_l1_count) / len(valid_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_regularized_sentence_length(old_df):\n",
    "    new_df = old_df.copy()\n",
    "    new_df['std_sentence_len'] = new_df.groupby(['essay_set'])[['sentence_length']].apply(lambda x: (x - np.mean(x)) / (np.std(x)))\n",
    "    return new_df\n",
    "\n",
    "def create_regularization_sentence_length(old_df):\n",
    "    #getting the number of datasets\n",
    "    max_essay_set = max(old_df['essay_set'])\n",
    "    #list of the regularized values\n",
    "    regularization_data = []\n",
    "    for i in range(max_essay_set+1):\n",
    "        mean = np.mean((old_df[old_df['essay_set'] == i + 1])['sentence_length'])\n",
    "        std = np.std((old_df[old_df['essay_set'] == i + 1])['sentence_length'])\n",
    "        regularization_data.append([i + 1, mean, std])\n",
    "    return regularization_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences(par):\n",
    "    split_sent = re.split(r'[.!?]+', par)\n",
    "    return len(split_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numOfSent_train = []\n",
    "for essay in train_df['essay']:\n",
    "    sent = sentences(essay)\n",
    "    numOfSent_train.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numOfSent_valid = []\n",
    "for essay in valid_df['essay']:\n",
    "    sent = sentences(essay)\n",
    "    numOfSent_valid.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['sentence_length'] = numOfSent_train\n",
    "valid_df['sentence_length'] = numOfSent_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.306655</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.993622</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.956794</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   score  std_score  sentence_length  \n",
       "0      8  -0.343483               17  \n",
       "1      9   0.306655               21  \n",
       "2      7  -0.993622               15  \n",
       "3     10   0.956794               28  \n",
       "4      8  -0.343483               31  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>Log_L2 predicted_scores</th>\n",
       "      <th>newly_predicted_scores_log_l2</th>\n",
       "      <th>Log_L1 predicted_scores</th>\n",
       "      <th>newly_predicted_scores_log_l1</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   score  Log_L2 predicted_scores  newly_predicted_scores_log_l2  \\\n",
       "0      7                        0                              8   \n",
       "1      8                        0                              8   \n",
       "2      9                        0                              8   \n",
       "3      9                        0                              8   \n",
       "4      9                        0                              8   \n",
       "\n",
       "   Log_L1 predicted_scores  newly_predicted_scores_log_l1  sentence_length  \n",
       "0                        0                              8               14  \n",
       "1                        0                              8               22  \n",
       "2                        0                              8               16  \n",
       "3                        0                              8               25  \n",
       "4                        0                              8               35  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regularization_data_sentence = create_regularization_sentence_length(train_df)\n",
    "train_df = append_regularized_sentence_length(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>std_sentence_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.761714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.306655</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.327943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.993622</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.978600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.956794</td>\n",
       "      <td>28</td>\n",
       "      <td>0.431156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "      <td>31</td>\n",
       "      <td>0.756484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   score  std_score  sentence_length  std_sentence_len  \n",
       "0      8  -0.343483               17         -0.761714  \n",
       "1      9   0.306655               21         -0.327943  \n",
       "2      7  -0.993622               15         -0.978600  \n",
       "3     10   0.956794               28          0.431156  \n",
       "4      8  -0.343483               31          0.756484  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Log Regression - Number of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1296: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=4,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_l2 = LogReg(penalty='l2', solver='liblinear', n_jobs=4)\n",
    "xs = [[x] for x in np.array(train_df['sentence_length'])]\n",
    "logistic_l2.fit(xs, train_std_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l2 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['sentence_length']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_l2.append(int(float(value) * float(regularization_data_sentence[i][2]) + (regularization_data_sentence[i][1])))\n",
    "\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['new_sentence_length_std'] = stand_pred_values_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My guess is we will want to denormalize these scores for quadratic weighted k\n",
    "valid_x = [[x] for x in np.array(valid_df['new_sentence_length_std'])]\n",
    "valid_pred_std_scores_l2 = logistic_l2.predict(valid_x)\n",
    "# Appending predicted scores to validation data set\n",
    "valid_df[\"Log_L2 predicted_scores\"] = valid_pred_std_scores_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l2 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['Log_L2 predicted_scores']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_l2.append(int(float(value) * float(regularization_data[i][2]) + (regularization_data[i][1])))\n",
    "# print stand_pred_values_l2\n",
    "\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['newly_predicted_scores_log_l2'] = stand_pred_values_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Log Regression - Number of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1296: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=4,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_l1 = LogReg(penalty='l1', solver='liblinear', n_jobs=4)\n",
    "logistic_l1.fit(xs, train_std_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My guess is we will want to denormalize these scores for quadratic weighted k\n",
    "valid_pred_std_scores_l1 = logistic_l1.predict(valid_x)\n",
    "# Appending predicted scores to validation data set\n",
    "valid_df[\"Log_L1 predicted_scores\"] = valid_pred_std_scores_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l1 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['Log_L1 predicted_scores']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_l1.append(int(float(value) * float(regularization_data[i][2]) + (regularization_data[i][1])))\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['newly_predicted_scores_log_l1'] = stand_pred_values_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring using Log Regression - Number of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC L2 using Feature: Number of Sentences\n",
      "Number of correct predictions = 974\n",
      "Total number of observations = 4218\n",
      "Score = 0.23091512565196776\n",
      "\n",
      "LOGISTIC L1 using Feature: Number of Sentences\n",
      "Number of correct predictions = 948\n",
      "Total number of observations = 4218\n",
      "Score = 0.22475106685633\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "#   Scoring   #\n",
    "###############\n",
    "\n",
    "#Scoring the predicted values with the actual values\n",
    "log_l1_count = 0\n",
    "log_l2_count = 0\n",
    "for i in range(len(valid_df)):\n",
    "    if valid_df.iloc[i]['score'] == valid_df.iloc[i]['newly_predicted_scores_log_l2']:\n",
    "        log_l2_count += 1\n",
    "    if valid_df.iloc[i]['score'] == valid_df.iloc[i]['newly_predicted_scores_log_l1']:\n",
    "        log_l1_count += 1\n",
    "        \n",
    "print (\"LOGISTIC L2 using Feature: Number of Sentences\")\n",
    "print (\"Number of correct predictions =\", log_l2_count)\n",
    "print (\"Total number of observations =\", len(valid_df))\n",
    "print (\"Score =\", float(log_l2_count) / len(valid_df))\n",
    "\n",
    "print (\"\")\n",
    "print (\"LOGISTIC L1 using Feature: Number of Sentences\")\n",
    "print( \"Number of correct predictions =\", log_l1_count)\n",
    "print (\"Total number of observations =\", len(valid_df))\n",
    "print (\"Score =\", float(log_l1_count) / len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "import pandas as pd\n",
    "#sys.setdefaultencoding('utf8')\n",
    "train_cols = ['essay_id', 'essay_set', 'essay', 'domain1_score', 'domain2_score']\n",
    "train_df = pd.read_csv('../../data/training_set_rel3.tsv', delimiter='\\t', encoding = \"ISO-8859-1\",usecols=train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
